{
 "metadata": {
  "name": "",
  "signature": "sha256:c27f804f0df7012d1c7991f610a2169bbecae017f2d4ecc24f542a3fc17fb30a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "import csv\n",
      "import numpy as np\n",
      "import random\n",
      "import scipy\n",
      "from scipy.spatial.distance import cosine\n",
      "from sklearn.feature_extraction.text import *\n",
      "from sklearn.metrics import *\n",
      "from sklearn.preprocessing import *\n",
      "from sklearn.svm import *\n",
      "\n",
      "TEST_FILE = '../data/testset.csv'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 126
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def recall(probas, k, group_size):    \n",
      "    n_batches = len(probas) // group_size\n",
      "    n_correct = 0\n",
      "    for i in xrange(n_batches):\n",
      "        batch = np.array(probas[i*group_size:(i+1)*group_size])\n",
      "        p = np.random.permutation(len(batch))\n",
      "        indices = p[np.argpartition(batch[p], -k)[-k:]]\n",
      "        indices = np.argpartition(batch, -k)[-k:]\n",
      "        if 0 in indices:\n",
      "            n_correct += 1\n",
      "    return n_correct / (len(probas) / group_size)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 133
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "C = []\n",
      "R = []\n",
      "Y = []\n",
      "for line in csv.reader(open(TEST_FILE), delimiter=','):\n",
      "    C.append(line[0])\n",
      "    R.append(line[1])\n",
      "    Y.append(int(line[2]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 128
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vectorizer = TfidfVectorizer()\n",
      "vectorizer.fit(C+R)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 129,
       "text": [
        "TfidfVectorizer(analyzer=u'word', binary=False, charset=None,\n",
        "        charset_error=None, decode_error=u'strict',\n",
        "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
        "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
        "        ngram_range=(1, 1), norm=u'l2', preprocessor=None, smooth_idf=True,\n",
        "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
        "        token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
        "        vocabulary=None)"
       ]
      }
     ],
     "prompt_number": 129
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "C_vec = vectorizer.transform(C)\n",
      "R_vec = vectorizer.transform(R)\n",
      "Y = np.array(Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 130
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def main(group_size):\n",
      "    batch_size = 10\n",
      "    n_batches = len(Y) // 10\n",
      "    probas = []\n",
      "    YY = []\n",
      "    for i in xrange(n_batches):\n",
      "        if i % 10000 == 0:\n",
      "            print i\n",
      "        batch_c = C_vec[i*batch_size:(i+1)*batch_size][:group_size]\n",
      "        batch_r = R_vec[i*batch_size:(i+1)*batch_size][:group_size]\n",
      "        batch_y = Y[i*batch_size:(i+1)*batch_size][:group_size]\n",
      "        YY.append(batch_y)\n",
      "        probas += [1 - cosine(batch_c[0].toarray(), r.toarray()) for r in batch_r]\n",
      "    for k in [1, 2, 5]:\n",
      "        if k < group_size:\n",
      "            print 'recall@%d: ' % k, recall(probas, k, group_size)\n",
      "    probas = np.array(probas)\n",
      "    pred = np.zeros(probas.shape)\n",
      "    pred[probas > 0.5] = 1\n",
      "    pred[probas <= 0.5] = 0\n",
      "    YY = np.concatenate(YY)\n",
      "    print classification_report(YY, pred)    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 131
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "main(10)\n",
      "main(2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "10000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "recall@1: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.4204\n",
        "recall@2:  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.545733333333\n",
        "recall@5:  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.735266666667\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       0.90      1.00      0.95    135000\n",
        "          1       0.98      0.01      0.03     15000\n",
        "\n",
        "avg / total       0.91      0.90      0.86    150000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0\n",
        "10000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "recall@1: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.721066666667\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       0.50      1.00      0.67     15000\n",
        "          1       1.00      0.01      0.03     15000\n",
        "\n",
        "avg / total       0.75      0.51      0.35     30000\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 132
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "main(10)\n",
      "main(2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "10000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "recall@1: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.419066666667\n",
        "recall@2:  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.5418\n",
        "recall@5:  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.704533333333\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       0.90      1.00      0.95    135000\n",
        "          1       0.98      0.01      0.03     15000\n",
        "\n",
        "avg / total       0.91      0.90      0.86    150000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0\n",
        "10000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "recall@1: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.6568\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       0.50      1.00      0.67     15000\n",
        "          1       1.00      0.01      0.03     15000\n",
        "\n",
        "avg / total       0.75      0.51      0.35     30000\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 134
    }
   ],
   "metadata": {}
  }
 ]
}