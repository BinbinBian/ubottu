{
 "metadata": {
  "name": "",
  "signature": "sha256:f56bbba3728c192bf57bf0704b1ec14d1e5d16edf95df174d7a029b1e5dddd59"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cPickle\n",
      "import lasagne\n",
      "import numpy as np\n",
      "import re\n",
      "import sys\n",
      "import theano\n",
      "import theano.tensor as T\n",
      "from collections import defaultdict, OrderedDict\n",
      "from theano.printing import Print as pp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Using gpu device 0: GeForce GT 650M\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class CNN(object):\n",
      "    def __init__(self,\n",
      "                 data,\n",
      "                 U,\n",
      "                 img_w=300,\n",
      "                 filter_sizes=[3,4,5],\n",
      "                 num_filters=100,\n",
      "                 batch_size=50,\n",
      "                 lr_decay=0.95,\n",
      "                 sqr_norm_lim=9,\n",
      "                 non_static=True):\n",
      "        self.data = data\n",
      "        self.batch_size = batch_size\n",
      "        img_h = data['train']['r'].shape[1]\n",
      "        print img_h\n",
      "        conv_layers = []\n",
      "        for filter_size in filter_sizes:\n",
      "            l_in = lasagne.layers.InputLayer(shape=(None, 1, img_h, img_w))\n",
      "            conv_layer = lasagne.layers.Conv2DLayer(\n",
      "                    l_in,\n",
      "                    num_filters=num_filters,\n",
      "                    filter_size=(filter_size, img_w),\n",
      "                    strides=(1,1),\n",
      "                    nonlinearity=lasagne.nonlinearities.rectify\n",
      "                    )\n",
      "            pool_layer = lasagne.layers.MaxPool2DLayer(\n",
      "                    conv_layer,\n",
      "                    ds=(img_h-filter_size+1, 1)\n",
      "                    )\n",
      "            conv_layers.append(pool_layer)\n",
      "            \n",
      "        hidden_size = len(conv_layers) * num_filters\n",
      "        l_hidden1 = lasagne.layers.ConcatLayer(conv_layers)\n",
      "        l_hidden2 = lasagne.layers.DenseLayer(l_hidden1, num_units=hidden_size, nonlinearity=lasagne.nonlinearities.tanh)\n",
      "        self.M = theano.shared(np.random.randn(hidden_size, hidden_size).astype(theano.config.floatX))\n",
      "\n",
      "        index = T.iscalar()\n",
      "        c = T.imatrix('c')\n",
      "        r = T.imatrix('r')\n",
      "        y = T.ivector('y')\n",
      "        embeddings = theano.shared(U, name='embeddings')\n",
      "        zero_vec_tensor = T.fvector()\n",
      "        self.zero_vec = np.zeros(img_w, dtype=theano.config.floatX)\n",
      "        self.set_zero = theano.function([zero_vec_tensor], updates=[(embeddings, T.set_subtensor(embeddings[0,:], zero_vec_tensor))])\n",
      "\n",
      "        c_input = embeddings[c.flatten()].reshape((c.shape[0], 1, c.shape[1], embeddings.shape[1]))\n",
      "        r_input = embeddings[r.flatten()].reshape((r.shape[0], 1, r.shape[1], embeddings.shape[1]))\n",
      "\n",
      "        e_context = l_hidden2.get_output(c_input)\n",
      "        e_response = l_hidden2.get_output(r_input)\n",
      "\n",
      "        o = T.nnet.sigmoid(T.batched_dot(T.dot(e_context, self.M), e_response))\n",
      "        o = T.clip(o, 1e-7, 1.0-1e-7)\n",
      "        #o = pp('o')(o)\n",
      "\n",
      "        cost = T.nnet.binary_crossentropy(o, y).mean()\n",
      "        params = lasagne.layers.get_all_params(l_hidden2) + [self.M]\n",
      "        if non_static:\n",
      "            params += [embeddings]\n",
      "        # TODO: limit norms\n",
      "        updates = lasagne.updates.adadelta(cost, params, learning_rate=1.0, rho=lr_decay)\n",
      "        \n",
      "        self.train_set_c = theano.shared(data['train']['c'], borrow=True)\n",
      "        self.train_set_r = theano.shared(data['train']['r'], borrow=True)\n",
      "        self.train_set_y = theano.shared(data['train']['y'], borrow=True)\n",
      "        self.val_set_c = theano.shared(data['val']['c'], borrow=True)\n",
      "        self.val_set_r = theano.shared(data['val']['r'], borrow=True)\n",
      "        self.val_set_y = theano.shared(data['val']['y'], borrow=True)\n",
      "        \n",
      "        probas = T.concatenate([o.reshape((-1,1)), (1-o).reshape((-1,1))], axis=1)        \n",
      "        pred = T.argmax(probas, axis=1)\n",
      "        errors = T.mean(T.neq(pred, y), dtype=theano.config.floatX)\n",
      "        \n",
      "        self.train_model = theano.function([index], cost, updates=updates,\n",
      "              givens={\n",
      "                c: self.train_set_c[index*batch_size:(index+1)*batch_size],\n",
      "                r: self.train_set_r[index*batch_size:(index+1)*batch_size],\n",
      "                y: self.train_set_y[index*batch_size:(index+1)*batch_size]})         \n",
      "        \n",
      "        self.val_model = theano.function([index], errors,\n",
      "             givens={\n",
      "                c: self.val_set_c[index * batch_size: (index + 1) * batch_size],\n",
      "                r: self.val_set_r[index * batch_size: (index + 1) * batch_size],\n",
      "                y: self.val_set_y[index * batch_size: (index + 1) * batch_size]})\n",
      "\n",
      "        self.test_model = theano.function([index], errors,\n",
      "                 givens={\n",
      "                    c: self.train_set_c[index * batch_size: (index + 1) * batch_size],\n",
      "                    r: self.train_set_r[index * batch_size: (index + 1) * batch_size],\n",
      "                    y: self.train_set_y[index * batch_size: (index + 1) * batch_size]})    \n",
      "\n",
      "        test_error = T.mean(T.neq(pred, y))\n",
      "        self.test_model_all = theano.function([c, r, y], test_error)   \n",
      "    \n",
      "    def train(self, n_epochs=100, shuffle_batch=True):\n",
      "        epoch = 0\n",
      "        best_val_perf = 0\n",
      "        val_perf = 0\n",
      "        test_perf = 0\n",
      "        cost_epoch = 0\n",
      "        \n",
      "        n_train_batches = self.data['train']['y'].shape[0] // self.batch_size\n",
      "        n_val_batches = self.data['val']['y'].shape[0] // self.batch_size\n",
      "        \n",
      "        test_set_c, test_set_r, test_set_y = self.data['test']['c'], self.data['test']['r'], self.data['test']['y']\n",
      "        while (epoch < n_epochs):\n",
      "            epoch += 1\n",
      "            indices = range(n_train_batches)\n",
      "            if shuffle_batch:\n",
      "                indices = np.random.permutation(indices)\n",
      "            for minibatch_index in indices:\n",
      "                cost_epoch = self.train_model(minibatch_index)\n",
      "                self.set_zero(self.zero_vec)\n",
      "            train_losses = [self.test_model(i) for i in xrange(n_train_batches)]\n",
      "            train_perf = 1 - np.mean(train_losses)\n",
      "            val_losses = [self.val_model(i) for i in xrange(n_val_batches)]\n",
      "            val_perf = 1 - np.mean(val_losses)                        \n",
      "            print 'epoch %i, train perf %f %%, val perf %f' % (epoch, train_perf * 100., val_perf*100.)\n",
      "            if val_perf >= best_val_perf:\n",
      "                best_val_perf = val_perf\n",
      "                test_loss = self.test_model_all(test_set_c, test_set_r, test_set_y)        \n",
      "                test_perf = 1 - test_loss         \n",
      "        return test_perf\n",
      "\n",
      "def sgd_updates_adadelta(params,cost,rho=0.95,epsilon=1e-6,norm_lim=9,word_vec_name='Words'):\n",
      "    updates = OrderedDict({})\n",
      "    exp_sqr_grads = OrderedDict({})\n",
      "    exp_sqr_ups = OrderedDict({})\n",
      "    gparams = []\n",
      "    for param in params:\n",
      "        empty = np.zeros_like(param.get_value())\n",
      "        exp_sqr_grads[param] = theano.shared(value=as_floatX(empty),name=\"exp_grad_%s\" % param.name)\n",
      "        gp = T.grad(cost, param)\n",
      "        exp_sqr_ups[param] = theano.shared(value=as_floatX(empty), name=\"exp_grad_%s\" % param.name)\n",
      "        gparams.append(gp)\n",
      "    for param, gp in zip(params, gparams):\n",
      "        exp_sg = exp_sqr_grads[param]\n",
      "        exp_su = exp_sqr_ups[param]\n",
      "        up_exp_sg = rho * exp_sg + (1 - rho) * T.sqr(gp)\n",
      "        updates[exp_sg] = up_exp_sg\n",
      "        step =  -(T.sqrt(exp_su + epsilon) / T.sqrt(up_exp_sg + epsilon)) * gp\n",
      "        updates[exp_su] = rho * exp_su + (1 - rho) * T.sqr(step)\n",
      "        stepped_param = param + step\n",
      "        if (param.get_value(borrow=True).ndim == 2) and (param.name!='Words'):\n",
      "            col_norms = T.sqrt(T.sum(T.sqr(stepped_param), axis=0))\n",
      "            desired_norms = T.clip(col_norms, 0, T.sqrt(norm_lim))\n",
      "            scale = desired_norms / (1e-7 + col_norms)\n",
      "            updates[param] = stepped_param * scale\n",
      "        else:\n",
      "            updates[param] = stepped_param      \n",
      "    return updates \n",
      " \n",
      "def get_idx_from_sent(sent, word_idx_map, max_l, k, filter_h):\n",
      "    \"\"\"\n",
      "    Transforms sentence into a list of indices. Pad with zeroes.\n",
      "    \"\"\"\n",
      "    x = []\n",
      "    pad = filter_h - 1\n",
      "    for i in xrange(pad):\n",
      "        x.append(0)\n",
      "    words = sent.split()\n",
      "    for word in words[:max_l]:\n",
      "        if word in word_idx_map:\n",
      "            x.append(word_idx_map[word])\n",
      "    while len(x) < max_l+2*pad:\n",
      "        x.append(0)\n",
      "    return x\n",
      "\n",
      "def make_idx_data(dataset, word_idx_map, max_l=152, k=300, filter_h=5):\n",
      "    \"\"\"\n",
      "    Transforms sentences into a 2-d matrix.\n",
      "    \"\"\"\n",
      "    for i in xrange(len(dataset['y'])):\n",
      "        dataset['c'][i] = get_idx_from_sent(dataset['c'][i], word_idx_map, max_l, k, filter_h)\n",
      "        dataset['r'][i] = get_idx_from_sent(dataset['r'][i], word_idx_map, max_l, k, filter_h)\n",
      "    for col in ['c', 'r', 'y']:\n",
      "        dataset[col] = np.array(dataset[col], dtype=np.int32)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"loading data...\",\n",
      "data = cPickle.load(open('data.pkl', 'rb'))\n",
      "train_data, val_data, test_data, W, W2, word_idx_map, vocab = data\n",
      "print \"data loaded!\"\n",
      "\n",
      "make_idx_data(train_data, word_idx_map)\n",
      "make_idx_data(val_data, word_idx_map)\n",
      "make_idx_data(test_data, word_idx_map)\n",
      "for key in ['c', 'r', 'y']:\n",
      "    print train_data[key].shape\n",
      "    print val_data[key].shape\n",
      "    print test_data[key].shape\n",
      "\n",
      "data = { 'train' : train_data, 'val': val_data, 'test': test_data }"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "loading data... "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data loaded!\n",
        "(9999, 160)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(27432, 160)\n",
        "(17546, 160)\n",
        "(9999, 160)\n",
        "(27432, 160)\n",
        "(17546, 160)\n",
        "(9999,)\n",
        "(27432,)\n",
        "(17546,)\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cnn = CNN(data,\n",
      "          W.astype(theano.config.floatX),\n",
      "          img_w=300,\n",
      "          filter_sizes=[3,4,5],\n",
      "          num_filters=100,\n",
      "          batch_size=2,\n",
      "          lr_decay=0.95,\n",
      "          sqr_norm_lim=9,\n",
      "          non_static=False)\n",
      "print cnn.train(n_epochs=10, shuffle_batch=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "160\n",
        "epoch 1, train perf 50.000000 %, val perf 50.000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "ename": "MemoryError",
       "evalue": "Error allocating 3368832000 bytes of device memory (out of memory).\nApply node that caused the error: GpuAdvancedSubtensor1(embeddings, Flatten{1}.0)\nInputs types: [CudaNdarrayType(float32, matrix), TensorType(int32, vector)]\nInputs shapes: [(34887, 300), (2807360,)]\nInputs strides: [(300, 1), (4,)]\nInputs values: ['not shown', 'not shown']\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-31-8ce2f3b17122>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m           \u001b[0msqr_norm_lim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m           non_static=False)\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m<ipython-input-30-d362051ecbf3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, n_epochs, shuffle_batch)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mval_perf\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mbest_val_perf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0mbest_val_perf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_perf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m                 \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_model_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m                 \u001b[0mtest_perf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtest_perf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/npow/anaconda/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    606\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthunks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                         storage_map=self.fn.storage_map)\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m                     \u001b[0;31m# For the c linker We don't have access from\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/npow/anaconda/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/npow/anaconda/lib/python2.7/site-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    779\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m                     \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/npow/anaconda/lib/python2.7/site-packages/theano/sandbox/cuda/basic_ops.pyc\u001b[0m in \u001b[0;36mperform\u001b[0;34m(self, node, inp, out_)\u001b[0m\n\u001b[1;32m   2550\u001b[0m                        \u001b[0mout_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# return\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2551\u001b[0m                        \u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2552\u001b[0;31m                        self.max_threads)\n\u001b[0m\u001b[1;32m   2553\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mx_orig\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2554\u001b[0m                 \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mMemoryError\u001b[0m: Error allocating 3368832000 bytes of device memory (out of memory).\nApply node that caused the error: GpuAdvancedSubtensor1(embeddings, Flatten{1}.0)\nInputs types: [CudaNdarrayType(float32, matrix), TensorType(int32, vector)]\nInputs shapes: [(34887, 300), (2807360,)]\nInputs strides: [(300, 1), (4,)]\nInputs values: ['not shown', 'not shown']\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}